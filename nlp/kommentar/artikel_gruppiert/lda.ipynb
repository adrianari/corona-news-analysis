{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis \n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import pymysql as mariadb\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import bokeh\n",
    "from bokeh.models import Circle, ColumnDataSource, Line, LinearAxis, Range1d, LabelSet, HoverTool\n",
    "from bokeh.palettes import d3\n",
    "import bokeh.models as bmo\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.core.properties import value\n",
    "from bokeh.palettes import viridis\n",
    "from bokeh.palettes import inferno\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=False))  # deacc=True removes punctuations\n",
    "        \n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('german')\n",
    "stop_words.extend([\"wieultimativwir\", \"vernetztsind\",\"dassinder\",\"buchauszug\",\"wirbeispielhaft\",\"diewie\", \"bild_watson\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establishing the dataframe\n",
    "connection = mariadb.connect(host=\"localhost\", database=\"masterarbeit\",\n",
    "                            user=\"USER\", password=\"PASSWORD\")\n",
    "\n",
    "#getting data\n",
    "sql = (\"SELECT * \"\n",
    "       \"FROM pasted \")\n",
    "\n",
    "df = pd.read_sql_query(sql, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"fj\"  # kürzel für betrachteten zeitraum\n",
    "b = 8     #anzahl cluster\n",
    "c = [2,2,5,2,2,2,5,2]    #anzahl subtopics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"art_date\"] = pd.to_datetime(df[\"art_date\"])\n",
    "df2 = df\n",
    "df2 = df2.set_index(df2[\"art_date\"])\n",
    "df2 = df2[df2.index.month.isin([1,2,3,4,5,6])]\n",
    "df = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features = 100000)\n",
    "vecs = vectorizer.fit_transform(df[\"text\"])\n",
    "\n",
    "kmeansmodel = KMeans(n_clusters = b, random_state=42).fit(vecs)\n",
    "df[\"labels\"] = kmeansmodel.labels_\n",
    "df3 = df.groupby([\"labels\", 'cat_res1'])[\"labels\"].count()\n",
    "df3.to_csv(\"comment_fully_\" + str(a) + \"_clustered.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_2d = np.array(pca.fit_transform(vecs.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[\"labels\"] = df[\"labels\"].astype(str)\n",
    "source = ColumnDataSource(data=dict(x=pca_2d[:,0], \n",
    "                                    y=pca_2d[:,1], \n",
    "                                    #label_field1=df['cat_res1'],\n",
    "                                    label_field2=df['labels'],\n",
    "                                    keys=df['labels']))\n",
    "\n",
    "hover = HoverTool(tooltips=[(\"ressort\", \"@label_field1\"), \n",
    "                            ('label', '@label_field2')])\n",
    "palette = inferno(len(df['labels'].unique()))\n",
    "color_map = bmo.CategoricalColorMapper(factors=df['labels'].unique(), \n",
    "                                       palette=palette)\n",
    "TOOLS = ['pan', 'wheel_zoom', 'reset', hover]\n",
    "p_pca = figure(title='Graphic representation of the clustering', tools=TOOLS, toolbar_location=\"left\")\n",
    "p_pca.scatter(x='x', \n",
    "              y='y', \n",
    "              size=2, \n",
    "              source=source,\n",
    "              color={'field': 'keys', 'transform': color_map},\n",
    "              legend_field='keys')\n",
    "\n",
    "output_file(\"clustered-kom\"+str(a)+\".html\")\n",
    "show(p_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [x for x in range(b)]\n",
    "num_subtopics = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in clusters:\n",
    "    print(num_subtopics[clusters.index(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x in clusters:\n",
    "    df4 = df.loc[df['labels'] == str(x)]\n",
    "\n",
    "    data_words = list(sent_to_words(df4[\"text\"]))\n",
    "\n",
    "    bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100)\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "    data_words_nostops = remove_stopwords(data_words)\n",
    "    data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Create Dictionary\n",
    "    id2word = corpora.Dictionary(data_words_bigrams)\n",
    "\n",
    "# Create Corpus\n",
    "    texts = data_words_bigrams\n",
    "\n",
    "# Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                               id2word=id2word,\n",
    "                                               num_topics=num_subtopics[clusters.index(x)], \n",
    "                                               random_state=42,\n",
    "                                               update_every=1,\n",
    "                                               chunksize=100,\n",
    "                                               passes=10,\n",
    "                                               alpha='auto',\n",
    "                                               per_word_topics=True\n",
    "                                               )\n",
    "    \n",
    "        \n",
    "    vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, R = 15, sort_topics = False)\n",
    "    pyLDAvis.save_html(vis, str(x)+\"-artikel-cluster\" + str(a) + \"lda.html\")\n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"LDA for Cluster No. \", x, \" likely containing \", num_subtopics[clusters.index(x)], \" subtopics with a perplexity of \", lda_model.log_perplexity(corpus))\n",
    "    pprint(lda_model.print_topics())\n",
    "    doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
