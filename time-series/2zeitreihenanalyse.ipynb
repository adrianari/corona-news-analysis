{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import statsmodels.tsa.stattools\n",
    "import statsmodels.graphics.tsaplots\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if this is the first time running the script, please let the next two lines commented to make sure the code works.\n",
    "#If the code runs, please feel free to uncomment and let the code rerun to ignore any warnings\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Time Frame\n",
    "\n",
    "Indicate below the range of months you are interested in. \n",
    "\n",
    "<b> Important </b> <br>\n",
    "<ul> \n",
    "<li> indicate the month indication in a non Python-way <br>\n",
    "    Code has been created in such a way that input will be interpreted as such. If you are interested in the entire year, do not put df_maker(1,13) (as you would do in a Python way) but df_maker(1,12). The code will understand.\n",
    "    <p>\n",
    "<li> code is implemented as range <br>\n",
    "    If you are interested in single months, you will need to establish two variables with single range.\n",
    "    Example: <br>\n",
    "    january = df_maker(1,1) <br>\n",
    "    august = df_maker(8,8) <br>\n",
    "    Kindly note that in this case, code will need to be run for each variable\n",
    "    <p>\n",
    "<li> comparison needs to be done manually <br>\n",
    "    if you are interested in comparing two different time frames, you will need to this manually\n",
    "    \n",
    "</ul>\n",
    "    \n",
    "<br>\n",
    "\n",
    "<b> Examples </b> <br>\n",
    "1,12 = entire year (January to December)<br>\n",
    "1,6 = first wave (January to June) <br>\n",
    "7, 12 = second wave (July to December) <br>\n",
    "3,5 = March to May<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = input(\"Please enter the starting month as a full number. (E.g. for January = 1)\")\n",
    "b = input(\"Please enter the ending month as a full number. (E.g. for December = 12)\")\n",
    "\n",
    "a = int(a)\n",
    "b = int(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up / Establishing Functions\n",
    "\n",
    "Below, functions and other parts for the code are established. No need to change anything, just let the cells run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data and data cleaning\n",
    "df = pd.read_csv(\"zeitreihe.csv\", delimiter = \",\")\n",
    "df = df.set_index(\"tage\")\n",
    "df = df.rename(columns = {\"0\": \"artikel_zahlen\", \n",
    "                          \"0_kom\" : \"kom_zahlen\", \n",
    "                          \"entries_fall\": \"bag_zahlen\", \n",
    "                          \"entries_hosp\" : \"hosp_zahlen\",\n",
    "                          \"entries_tod\": \"tod_zahlen\"})\n",
    "df = df.fillna(0)\n",
    "df = df.reset_index()\n",
    "df[\"month\"] = pd.to_datetime(df[\"tage\"]).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_maker(a,b):\n",
    "    \"\"\"\n",
    "    Creates the df based on the month range of interest\n",
    "    \"\"\"\n",
    "    months_of_interest = [x for x in range(a,b+1)]\n",
    "\n",
    "    df1 = df[df[\"month\"].isin(months_of_interest)].set_index(\"tage\").drop([\"month\"], axis = 1)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_values(df): \n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates the metrics for the undifferentiated dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    #shapiro\n",
    "    shapiro_dict = {\"name\" : [\"shapiro-statistic\", \"shapiro-pvalue\"]}\n",
    "    for column in df:\n",
    "        x = column\n",
    "        y = scipy.stats.shapiro(df[column])\n",
    "        shapiro_dict[x] = [y.statistic, y.pvalue]\n",
    "\n",
    "    shapiro_df = pd.DataFrame.from_dict(shapiro_dict)\n",
    "    main_df = shapiro_df\n",
    "    \n",
    "    \n",
    "    #test for stationarity via Augmented Dicky Fuller\n",
    "\n",
    "    adf_dict = {\"name\" : [\"adf-statistics\", \"adf-pvalue\", \"adf-lags\", \"adf-nobs\", \"adf-critical-values\"]}\n",
    "    for column in df:\n",
    "        x = column\n",
    "        y = statsmodels.tsa.stattools.adfuller(df[column])\n",
    "        adf_dict[x] = [y[0], y[1], y[2], y[3], y[4]]\n",
    "\n",
    "    adf_df = pd.DataFrame.from_dict(adf_dict)\n",
    "    main_df = main_df.append(adf_df)\n",
    "    \n",
    "    #test for stationarity via KPSS\n",
    "    kpss_dict = {\"name\" : [\"kpss-statistics\", \"kpss-pvalue\", \"kpss-lags\", \"kpss-critvalues\"]}\n",
    "    for column in df:\n",
    "        x = column\n",
    "        y = statsmodels.tsa.stattools.kpss(df[column])\n",
    "        kpss_dict[x] = [y[0], y[1], y[2], y[3]]\n",
    "\n",
    "    kpss_df = pd.DataFrame.from_dict(kpss_dict)\n",
    "    main_df = main_df.append(kpss_df)\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlater(df):\n",
    "\n",
    "    #Spearman correlation\n",
    "\n",
    "    todo = [[df.bag_zahlen, df.artikel_zahlen], [df.bag_zahlen, df.kom_zahlen], \n",
    "            [df.tod_zahlen, df.artikel_zahlen], [df.tod_zahlen, df.kom_zahlen],\n",
    "            [df.hosp_zahlen, df.artikel_zahlen], [df.hosp_zahlen, df.kom_zahlen],\n",
    "            [df.artikel_zahlen, df.kom_zahlen]]\n",
    "    cor_dict = {\"name\" : [\"spearman-statistic\", \"spearman-pvalue\"]}\n",
    "\n",
    "    for element in todo:\n",
    "        a = element[0].name\n",
    "        b = element[1].name\n",
    "        x = element[0]\n",
    "        y = element[1]\n",
    "        z = scipy.stats.spearmanr(x,y)\n",
    "        cor_dict[(a, b)] = [\"{:.6f}\".format(float(z.correlation)), \"{:.6f}\".format(float(z.pvalue))]\n",
    "\n",
    "    cor_df = pd.DataFrame.from_dict(cor_dict)\n",
    "    \n",
    "    \n",
    "    #just for fun we check pearson nonetheless\n",
    "\n",
    "    pearson_dict = {\"name\" : [\"pearson-tail1\", \"pearson-tail2\"]}\n",
    "\n",
    "    for element in todo:\n",
    "        a = element[0].name\n",
    "        b = element[1].name\n",
    "        x = element[0]\n",
    "        y = element[1]\n",
    "        z = scipy.stats.pearsonr(x,y)\n",
    "        pearson_dict[(a, b)] = z\n",
    "\n",
    "    pearson_df = pd.DataFrame.from_dict(pearson_dict)\n",
    "    cor_df = cor_df.append(pearson_df)\n",
    "    cor_df = cor_df.reset_index()\n",
    "    cor_df = cor_df.drop(columns = \"index\")\n",
    "    return cor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diffentiating \n",
    "\n",
    "def differentiate(df):\n",
    "    \"\"\"\n",
    "    Differentiates all columns in the dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    diff_bag = np.diff(df[\"bag_zahlen\"])\n",
    "    diff_artikel = np.diff(df.artikel_zahlen)\n",
    "    diff_kom = np.diff(df.kom_zahlen)\n",
    "    diff_tod = np.diff(df.tod_zahlen)\n",
    "    diff_hosp = np.diff(df.hosp_zahlen)\n",
    "\n",
    "\n",
    "\n",
    "    diff_df = pd.DataFrame(data = [diff_artikel, diff_kom, diff_bag, diff_tod, diff_hosp])\n",
    "    diff_df = diff_df.transpose()\n",
    "    diff_df = diff_df.rename(columns = {0:\"diff_artikel\", 1:\"diff_komm\", 2:\"diff_bag\", 3:\"diff_tod\", 4:\"diff_hosp\"})\n",
    "\n",
    "    for x in diff_df:\n",
    "        diff_df[x] = diff_df[x].astype(float)\n",
    "    \n",
    "    return diff_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_tester(diff_df):\n",
    "    \"\"\"\n",
    "    Tests a (differentiated) dataframe for stationarity only. (Without the correlation etc. from the previous function)\n",
    "    \"\"\"\n",
    "    #retesting for stationarity (ADF)\n",
    "    diff_adf_dict = {\"name\" : [\"adf-statistics-diff\", \"adf-pvalue-diff\", \"adf-lags-diff\", \"adf-nobs-diff\", \"adf-critical-values-diff\"]}\n",
    "    for column in diff_df:\n",
    "        x = column\n",
    "        y = statsmodels.tsa.stattools.adfuller(diff_df[column])\n",
    "        diff_adf_dict[x] = [y[0], y[1], y[2], y[3], y[4]]\n",
    "\n",
    "    diff_adf_df = pd.DataFrame.from_dict(diff_adf_dict)\n",
    "    diff_main_df = diff_adf_df\n",
    "    \n",
    "    #test for stationarity via KPSS\n",
    "    diff_kpss_dict = {\"name\" : [\"kpss-statistics-diff\", \"kpss-pvalue-diff\", \"kpss-lags-diff\", \"kpss-critvalues-diff\"]}\n",
    "    for column in diff_df:\n",
    "        x = column\n",
    "        y = statsmodels.tsa.stattools.kpss(diff_df[column])\n",
    "        diff_kpss_dict[x] = [y[0], y[1], y[2], y[3]]\n",
    "\n",
    "    diff_kpss_df = pd.DataFrame.from_dict(diff_kpss_dict)\n",
    "    diff_main_df = diff_main_df.append(diff_kpss_df)\n",
    "    \n",
    "    return diff_main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acf_maker(x_diff):\n",
    "    \"\"\"\n",
    "    Shows the auto-correlation of the single time series.\n",
    "    \"\"\"\n",
    "    \n",
    "    acf_list = [x_diff.diff_bag, x_diff.diff_artikel, x_diff.diff_komm, x_diff.diff_tod, x_diff.diff_hosp]\n",
    "\n",
    "    for y in acf_list:\n",
    "        fig, ax2 = plty.subplots(1, 1)\n",
    "        ax2.acorr(y, usevlines=True, normed=True, maxlags=28, lw=2)\n",
    "        try:\n",
    "            fig.suptitle(str(y.name))\n",
    "        except AttributeError:\n",
    "            fig.suptitle(\"BAG Diff Diff\")\n",
    "        ax2.grid(True)\n",
    "\n",
    "        plty.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pacf_maker(x_diff):\n",
    "    \"\"\"\n",
    "    Shows the partial auto-correlation of the single time series.\n",
    "    \"\"\"\n",
    "    \n",
    "    pacf_list = [x_diff.diff_bag, x_diff.diff_artikel, x_diff.diff_komm, x_diff.diff_tod, x_diff.diff_hosp]\n",
    "\n",
    "    for y in pacf_list:\n",
    "        statsmodels.graphics.tsaplots.plot_pacf(y, title = \"Partial Autocorrelation - \" + str(y.name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_correlate(diff_df):\n",
    "    \n",
    "    \"\"\"\n",
    "    OPTIONAL TO GET MORE INSIGHT.\n",
    "    Get the crosscorrelation.\n",
    "    Input should be a stationary dataframe.\n",
    "    \n",
    "    Visualizes the different crosscorrelations in one illustration as well as makes a pairplot of the columns as descirbed here\n",
    "    https://towardsdatascience.com/visualizing-data-with-pair-plots-in-python-f228cf529166\n",
    "    \"\"\"\n",
    "    \n",
    "    #Cross correlation\n",
    "\n",
    "    todo_diff = [[diff_df.diff_bag, diff_df.diff_artikel], [diff_df.diff_bag, diff_df.diff_komm], \n",
    "                 [diff_df.diff_tod, diff_df.diff_artikel], [diff_df.diff_tod, diff_df.diff_komm],\n",
    "                 [diff_df.diff_hosp, diff_df.diff_artikel],  [diff_df.diff_hosp,diff_df.diff_komm],\n",
    "                 [diff_df.diff_artikel, diff_df.diff_komm]]\n",
    "    ccf_dict = {}\n",
    "\n",
    "    for element in todo_diff:\n",
    "        a = element[0].name\n",
    "        b = element[1].name\n",
    "        x = element[0]\n",
    "        y = element[1]\n",
    "        z = statsmodels.tsa.stattools.ccf(x,y)\n",
    "        ccf_dict[str(a) + \"-\" + str(b)] = z\n",
    "\n",
    "    ccf_df = pd.DataFrame.from_dict(ccf_dict)\n",
    "    ccf_df.to_csv(\"cross_correlations_full.csv\", sep= \";\")\n",
    "    \n",
    "    ccf_df.plot()\n",
    "    sns.pairplot(diff_df)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FALLZAHLEN\n",
    "def fall(diff_df):\n",
    "    \n",
    "    fig, axs = plty.subplots(nrows = 2, sharey = True)\n",
    "    fig.suptitle('Kreuzkorrelation ∆Fallzahlen <-> ∆Artikelzahlen (oben), ∆Kommentarzahlen(unten)')\n",
    "    \n",
    "    axs[0].xcorr(diff_df.diff_bag, \n",
    "                     diff_df.diff_artikel)    \n",
    "    axs[1].xcorr(diff_df.diff_bag, diff_df.diff_komm)\n",
    "\n",
    "\n",
    "\n",
    "#TODESZAHLEN\n",
    "def tod(diff_df):  \n",
    "    \n",
    "    fig, axs = plty.subplots(nrows = 2, sharey = True)\n",
    "    fig.suptitle('Kreuzkorrelation ∆Todeszahlen <-> ∆Artikelzahlen (oben), ∆Kommentarzahlen(unten)')\n",
    "    \n",
    "    axs[0].xcorr(diff_df.diff_tod, diff_df.diff_artikel)\n",
    "    axs[1].xcorr(diff_df.diff_tod, diff_df.diff_komm)\n",
    "    \n",
    "    \n",
    "#HOSPITALISIERUNGSZAHLEN\n",
    "def hosp(diff_df):\n",
    "    \n",
    "    fig, axs = plty.subplots(nrows = 2, sharey = True)\n",
    "    fig.suptitle('Kreuzkorrelation ∆Hospitalisierungszahlen <-> ∆Artikelzahlen (oben), ∆Kommentarzahlen(unten)')\n",
    "    \n",
    "\n",
    "    axs[0].xcorr(diff_df.diff_hosp, diff_df.diff_artikel)\n",
    "\n",
    "    axs[1].xcorr(diff_df.diff_hosp, diff_df.diff_komm)\n",
    "\n",
    "    \n",
    "    \n",
    "#ARTIKEL\n",
    "def art_komm(diff_df):\n",
    "    \n",
    "    \n",
    "    plt.pyplot.xcorr(diff_df.diff_artikel, diff_df.diff_komm)\n",
    "    plt.pyplot.title(\"Kreuzkorrelation ∆Artikelzahlen <-> ∆Kommentarzahlen\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_shower(df):\n",
    "    \"\"\"\n",
    "    Shows all the crosscorrelation plots, based on the assumption that the columns in the dataframe need to be\n",
    "    differentiated once\n",
    "    \"\"\"\n",
    "    art_komm(differentiate(df))\n",
    "    fall(differentiate(df))\n",
    "    hosp(differentiate(df))\n",
    "    tod(differentiate(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagger(x):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get the number of lags.\n",
    "    We work here with the undifferentiated dataset!\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    model = VAR(x)\n",
    "    darste = []\n",
    "    nummer = []\n",
    "    for i in [1,2,3,4,5,6,7,8,9,10, 11, 12, 13, 14, 15, 16, 17, 18 ,19, 20, 21,22, 23,24]:\n",
    "        result = model.fit(i)\n",
    "        try:\n",
    "            #print('Lag Order =', i)\n",
    "            #print('AIC : ', result.aic)\n",
    "            \n",
    "            darste.append(result.aic)\n",
    "            nummer.append(i)\n",
    "    #        print('BIC : ', result.bic)\n",
    "     #       print('FPE : ', result.fpe)\n",
    "      #      print('HQIC: ', result.hqic, '\\n')\n",
    "        except:\n",
    "            print(nummer)\n",
    "            print(darste)\n",
    "            continue\n",
    "\n",
    "    plty.title(\"Akaike Information Criterion, indicating optimal lag\")\n",
    "    plty.plot(nummer, darste)\n",
    "    plty.grid(axis = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitter(x_diff,y):    \n",
    "    \n",
    "    \"\"\"\n",
    "    input of this function = optimal number of lags as from lagger(x_diff)\n",
    "    \"\"\"\n",
    "    model = VAR(x_diff)\n",
    "    model_fitted = model.fit(y)\n",
    "    model_fitted\n",
    "\n",
    "\n",
    "    out = durbin_watson(model_fitted.resid)\n",
    "\n",
    "    \n",
    "    print(\"Serial Correlation of Residuals using Durbin Watson Statistic\")\n",
    "    for col, val in zip(x_diff.columns, out):\n",
    "        print(col, ':', round(val, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grangers_causation_matrix(data, variables, test='ssr_chi2test', verbose=False):\n",
    "    \n",
    "    #https://rishi-a.github.io/2020/05/25/granger-causality.html\n",
    "    \n",
    "    \"\"\"Check Granger Causality of all possible combinations of the Time series.\n",
    "    The rows are the response variable, columns are predictors. The values in the table \n",
    "    are the P-Values. P-Values lesser than the significance level (0.05), implies \n",
    "    the Null Hypothesis that the coefficients of the corresponding past values is \n",
    "    zero, that is, the X does not cause Y can be rejected.\n",
    "\n",
    "    data      : pandas dataframe containing the time series variables\n",
    "    variables : list containing names of the time series variables.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    for c in df.columns:\n",
    "        for r in df.index:\n",
    "            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n",
    "            if verbose: \n",
    "                print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
    "            min_p_value = np.min(p_values)\n",
    "            df.loc[r, c] = min_p_value\n",
    "    df.columns = [var + '_x' for var in variables]\n",
    "    df.index = [var + '_y' for var in variables]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "We now get to the results. Below cell creates a timeframe according to your input in the top of this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_maker(\n",
    "    a,    #starting month\n",
    "    b    #ending month\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Figures\n",
    "\n",
    "Get key figures such as correlation and stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sin = single_values(x)\n",
    "x_sin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "\n",
    "We check the correlation of the time series of interest in terms of Pearson as well as Spearman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlater(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiating\n",
    "\n",
    "This step is done under the assumption that the previous step showed the input to be non-stationary and thus differentiates the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_diff = differentiate(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retest for stationiarity\n",
    "\n",
    "We retest for stationarity - now with the freshly differentiated input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_tester(x_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation\n",
    "\n",
    "We check whether the time series correlate with themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf_maker(x_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacf_maker(x_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cor_shower(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Granger Causality\n",
    "\n",
    "#### Getting the number of lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagger(x)\n",
    "\n",
    "fitter(x_diff, 7)   #basing on the plot and the elbow from lagger(x_diff), we take 7 (in the example). \n",
    "                    #In case the plot shows something different to you, use this number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual Granger Causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlag = 7\n",
    "o = grangers_causation_matrix(x_diff, variables = x_diff.columns)  \n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
