{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pickle\n",
    "import sys\n",
    "import re\n",
    "#from pymongo import MongoClient\n",
    "#import pymongo\n",
    "#import dns \n",
    "import csv\n",
    "\n",
    "modulename = \"dnspython\"\n",
    "if modulename not in sys.modules:\n",
    "    print('You have not imported the {} module'.format(modulename))\n",
    "else:\n",
    "    print('You have imported the {} module'.format(modulename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawled_liste = []\n",
    "\n",
    "class Article:\n",
    "    def __init__(self, title, lead, datum, author, text, url):\n",
    "        self.title = title\n",
    "        self.lead = lead\n",
    "        self.datum = datum\n",
    "        self.author = author\n",
    "        self.text = text\n",
    "        self.url = url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inhalter():    \n",
    "    #main\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    #segments\n",
    "    title = soup.find(class_=\"maintitle\").get_text()\n",
    "\n",
    "    ## lead (as it is not optional to have one)\n",
    "    lead = soup.find_all(class_=\"lead\")\n",
    "    if len(lead) >= 2:\n",
    "        lead = lead[0].get_text()\n",
    "    else:\n",
    "        lead = \"\"\n",
    "\n",
    "    # Datum (is not always given)\n",
    "    try:\n",
    "        datum = soup.find(class_=\"publish_date\").get_text()\n",
    "        datum = datum[:16]\n",
    "    except AttributeError:\n",
    "        datum = \"\"\n",
    "    \n",
    "    ## Author\n",
    "    try:\n",
    "        author = soup.find(class_=re.compile(\"author\")).get_text()\n",
    "        author = author[0:36].strip().get_text()\n",
    "    except AttributeError:\n",
    "        author = \"Agentur\"\n",
    "    \n",
    "    ## Text\n",
    "    text = str()\n",
    "    blocktext = soup.find_all(\"p\")\n",
    "    for teil in blocktext:\n",
    "        texty = teil.get_text()\n",
    "        texty = texty.replace('\\t','')\n",
    "        texty = texty.replace('\\n','')\n",
    "        text += \" \" + texty\n",
    "    \n",
    "    #URL\n",
    "    ding_url = example\n",
    "    \n",
    "    crawled = Article(title, lead, datum, author, text, ding_url)\n",
    "    crawled_liste.append(crawled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()\n",
    "driver.implicitly_wait(30)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_seite = \"https://www.watson.ch/\"\n",
    "beispiel =[\"https://www.watson.ch/digital/wirtschaft/716343328-wie-gross-ist-das-risiko-eines-blackouts-das-sagt-der-bund\",  \"https://www.watson.ch/international/donald%20trump/623748967-us-senat-spricht-ex-praesident-trump-im-amtsenthebungsverfahren-frei\"]\n",
    "\n",
    "driver.get(start_seite)\n",
    "\n",
    "cookies = pickle.load(open(\"watson_cookies.pkl\", \"rb\"))\n",
    "for cookie in cookies:\n",
    "    driver.add_cookie(cookie)\n",
    "    \n",
    "driver.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_seiten = []\n",
    "\n",
    "with open(\"watson_output.bin\", \"rb\") as data:\n",
    "    ueb_pages = pickle.load(data)\n",
    "    \n",
    "mismatch = \"https://www.watson.chhtt\"\n",
    "for x in ueb_pages:\n",
    "    if mismatch in x:\n",
    "        print(x)\n",
    "    else:\n",
    "        final_seiten.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in final_seiten[2955:]:\n",
    "    time.sleep(3)\n",
    "    driver.get(example)\n",
    "    try:\n",
    "        inhalter()\n",
    "    except TimeoutException:\n",
    "        print(\"TimeOut\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('watson_art4.csv', 'w', newline='', encoding=\"utf8\") as csvfile:\n",
    "    blogwriter = csv.writer(csvfile, delimiter='|', quotechar='\"')\n",
    "\n",
    "\n",
    "    for article in crawled_liste:\n",
    "        blogwriter.writerow( [article.title, article.lead, article.datum, article.author, article.text, article.url] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
